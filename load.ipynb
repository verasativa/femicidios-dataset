{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos con reglas de donde empieza la cabecera y si hay que cortar la cola de suicidios\n",
    "# y renombramos columnas\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "files = [\n",
    "    'data/Copia-de-femicidios_2010-1.xlsx',\n",
    "    'data/Copia-de-femicidios_2011.xlsx',\n",
    "    'data/Copia-de-femicidios_2012.xlsx',\n",
    "    'data/Copia-de-femicidios_2013.xlsx',\n",
    "    'data/Copia-de-femicidios2014final.xlsx',\n",
    "    'data/Femicidios-2015-1-2.xlsx',\n",
    "    'data/Femicidios-2016.xls',\n",
    "    'data/Femicidios 2017 - Red Chilena contra la Violencia hacia las Mujeres - FEMICIDIOS 2017.csv',\n",
    "    'data/Femicidios 2018 - Red Chilena contra la Violencia hacia las Mujeres - FEMICIDIOS 2018.csv',\n",
    "    'data/Femicidios 2019 - Red Chilena contra la Violencia hacia las Mujeres - FEMICIDIOS 2019.csv'\n",
    "]\n",
    "line_1_files = [\n",
    "    'data/Femicidios-2016.xls',\n",
    "    'data/Femicidios 2017 - Red Chilena contra la Violencia hacia las Mujeres - FEMICIDIOS 2017.csv',\n",
    "]\n",
    "trim_files = [\n",
    "    'data/Femicidios 2017 - Red Chilena contra la Violencia hacia las Mujeres - FEMICIDIOS 2017.csv',\n",
    "    'data/Femicidios 2019 - Red Chilena contra la Violencia hacia las Mujeres - FEMICIDIOS 2019.csv'\n",
    "]\n",
    "cols_rename = {\n",
    "    'Antecedentes Judiciales': 'Antecedentes',\n",
    "    'Antecedentes judiciales': 'Antecedentes',\n",
    "    'Relación ': 'Relación',\n",
    "    'Categoria Delito/Ley Femic.': 'Categoría delito/ Ley Femicidio',\n",
    "    'Categoria Delito': 'Categoría delito/ Ley Femicidio',\n",
    "    'Categoria Delito': 'Categoría delito/ Ley Femicidio',\n",
    "    'Categoria delito ': 'Categoría delito/ Ley Femicidio',\n",
    "    'Denuncia/ M cautelar': 'Denuncia/M cautelar',\n",
    "    'Ocupación ': 'Ocupación femicida',\n",
    "    'Edad ': 'Edad',\n",
    "    'Ocupación.1': 'Ocupación femicida',\n",
    "    'Edad.1': 'Edad femicida',\n",
    "    'Edad .1': 'Edad femicida',\n",
    "    'Edad 1': 'Edad femicida',\n",
    "    'Antecedentes ': 'Antecedentes',\n",
    "    'Fecha y Lugar': 'Fecha y lugar',\n",
    "    'Femicidia': 'Femicida',\n",
    "    'Nacionalidad / Etnia.1': 'Nacionalidad / Etnia femicida',\n",
    "    'Unnamed: 24': 'Información medios',\n",
    "    'Unnamed: 25': 'Información medios 2',\n",
    "}\n",
    "cols_delete = [\n",
    "    'Unnamed: 15',\n",
    "    'Unnamed: 16',\n",
    "    'Unnamed: 0',\n",
    "]\n",
    "dataframes = []\n",
    "for file in files:\n",
    "    if file in line_1_files:\n",
    "        header_line = 1\n",
    "    else:\n",
    "        header_line = 2\n",
    "    if file.split('.')[-1] == 'csv':\n",
    "        current_df = pd.read_csv(file, header=header_line)\n",
    "    else:\n",
    "        current_df = pd.read_excel(file, header=header_line, dtype={'Fecha y lugar': str})\n",
    "    for column in current_df:\n",
    "        for col_rename in cols_rename:\n",
    "            if column == col_rename:\n",
    "                current_df.rename(columns={column: cols_rename[column]}, inplace=True)\n",
    "        for col_delete in cols_delete:\n",
    "            if column == col_delete:\n",
    "                del current_df[column]\n",
    "    current_df['source'] = file\n",
    "    if file in trim_files:\n",
    "        current_df = current_df[:-3] #Cola de suicidios \n",
    "    dataframes.append(current_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat(dataframes, sort=False).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO:\n",
    "# - parse / make array references\n",
    "# - check categorical values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Triming month: 1-\n",
      "Not able to parse place:\n",
      "27/03\n",
      "Failed date:\n",
      "2013 0 20\n",
      "Failed date:\n",
      "2013 0 20\n",
      "Not able to parse place:\n",
      "21/04\n",
      "Not able to parse place:\n",
      "22/10\n"
     ]
    }
   ],
   "source": [
    "def parse_fecha_lugar(row):\n",
    "    if pd.notnull(row['Fecha y lugar']):\n",
    "        # Casos particulares\n",
    "        if row['Fecha y lugar'] == 'Collipulli12/12/2015':\n",
    "            row['Fecha y lugar'] = '12/12/2015 Collipulli'\n",
    "        if row['Fecha y lugar'] == '27/07Calama':\n",
    "            row['Fecha y lugar'] = '27/07 Calama'\n",
    "        if row['Fecha y lugar'] == '17/10PuertoMontt':\n",
    "            row['Fecha y lugar'] = '17/10 PuertoMontt'\n",
    "        if row['Fecha y lugar'] == 'Descubierto 25/09 Puerto Montt':\n",
    "            row['Fecha y lugar'] = '25/09 Puerto Montt'\n",
    "        if row['Fecha y lugar'] == '2015-11-21':\n",
    "            row['Fecha y lugar'] = '21/11'\n",
    "            \n",
    "        \n",
    "        \n",
    "        # Para capturar la fecha\n",
    "        spacers = ['.', '/ ','/',', ',',']\n",
    "        for spacer in spacers:\n",
    "            if row['Fecha y lugar'][:5].find(spacer) > 0:\n",
    "                tmp_date = {}\n",
    "                day = row['Fecha y lugar'][:5].split(spacer)[0]\n",
    "                month = row['Fecha y lugar'][:5].split(spacer)[1][:2].strip()\n",
    "                if (len(month) > 1):\n",
    "                    if not month[1].isdigit():\n",
    "                        print('Triming month: '+ month)\n",
    "                        month = month[0]\n",
    "                tmp = [int(s) for s in row['source'] if s.isdigit()][:4]\n",
    "                year = \"\".join(str(x) for x in tmp)\n",
    "                try:\n",
    "                    row['Fecha'] = pd.to_datetime(int(year) * 10000 + int(month) * 100 + int(day),format='%Y%m%d')\n",
    "                except:\n",
    "                    print('Failed date:')\n",
    "                    print(year, month, day)\n",
    "                #print(row['Fecha y lugar'])\n",
    "                \n",
    "        dividers = [' - ', '- ', ' ', '-']   \n",
    "        # Para capturar el lugar\n",
    "        found_lugar = False\n",
    "        for divider in dividers:\n",
    "            if (row['Fecha y lugar'].find(divider) > 0) and (not found_lugar):\n",
    "                row['Lugar'] = \" \".join(row['Fecha y lugar'].split(divider)[1:])\n",
    "                found_lugar = True\n",
    "                \n",
    "        if not found_lugar:\n",
    "            print('Not able to parse place:')\n",
    "            print(row['Fecha y lugar'])\n",
    "    else:\n",
    "        row['Fecha y lugar'] = pd.to_datetime(row['Fecha y lugar'])\n",
    "            \n",
    "    return row\n",
    "#bar = df.sample(n=100).apply(parse_fecha_lugar, axis=1)\n",
    "df_parsed = df.apply(parse_fecha_lugar, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_parsed.rename(columns={\n",
    "    'Fecha y lugar': 'old_fecha_y_lugar',\n",
    "    'Lugar': 'old_lugar',\n",
    "    'Región': 'old_region'\n",
    "}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "lugar_replacements = {\n",
    "    'Valpo': 'Valparaíso',\n",
    "    'Valparaiso': 'Valparaíso',\n",
    "    'Buín': 'Buin',\n",
    "    'Conchali': 'Conchalí',\n",
    "    'San Bdo': 'San Bernardo',\n",
    "    'Los Angeles': 'Los Ángeles',\n",
    "    'Santiago Centro': 'Santiago',\n",
    "    'Pto Montt': 'Puerto Montt',\n",
    "    'Pto. Montt': 'Puerto Montt',\n",
    "    'PuertoMontt': 'Puerto Montt',\n",
    "    'Labranza': 'Temuco',\n",
    "    'Padre Las Casas': 'Padre las Casas',\n",
    "    'Padre Casas': 'Padre las Casas',\n",
    "    'Tal Tal': 'Taltal',\n",
    "    'Con-con': 'Concón',\n",
    "    'Lontué': 'Molina',\n",
    "    'Entre Lagos': 'Puyehue',\n",
    "    'Est. Central': 'Estación Central',\n",
    "    'Llolleo, San Antonio': 'San Antonio',\n",
    "    'Pte Alto': 'Puente Alto',\n",
    "    'Pte. Alto': 'Puente Alto',\n",
    "    'Lautaro Temuco': 'Lautaro',\n",
    "    'Batuco': 'Lampa',\n",
    "    'Bucalemu, Paredones': 'Paredones',\n",
    "    'Carrizal, San Javier': 'San Javier',\n",
    "    'Cisterna': 'La Cisterna',\n",
    "    'Cohihueco': 'Coihueco',\n",
    "    'Dichato, Tomé': 'Tomé',\n",
    "    'El Olivar': 'Olivar',\n",
    "    'Hualaihue': 'Hualaihué',\n",
    "    'Huentelolen': 'Cañete',\n",
    "    'Indpenedencia': 'Independencia',\n",
    "    'Lanco Los Lagos': 'Los Lagos',\n",
    "    'LimacheV': 'Limache',\n",
    "    'Liquiñe': 'Panguipulli',\n",
    "    'Longavì': 'Longaví',\n",
    "    'LosAndes': 'Los Andes',\n",
    "    'Macúl': 'Macul',\n",
    "    'Neltume': 'Panguipulli',\n",
    "    'PAC': 'Pedro Aguirre Cerda',\n",
    "    'Pemuco/Ñuble': 'Ñuble',\n",
    "    'Peñalolen': 'Peñalolén',\n",
    "    'Pitrufquen': 'Pitrufquén',\n",
    "    'Pta.Arenas': 'Punta Arenas',\n",
    "    'Pto. Aysen': 'Aysén',\n",
    "    'Puerto Aysén': 'Aysén',\n",
    "    'Puero Varas': 'Puerto Varas',\n",
    "    'Puerto Cisnes': 'Cisnes',\n",
    "    'Quellon': 'Quellón',\n",
    "    'Quilpue': 'Quilpué',\n",
    "    'Quinquehua': 'San Carlos',\n",
    "    'Rallenco': 'Tirúa',\n",
    "    'Rapel': 'Navidad',\n",
    "    'Reinaco': 'Renaico',\n",
    "    'Romero, Serena': 'La Serena',\n",
    "    'San Francisco de Mostazal': 'Mostazal',\n",
    "    'San José de la Mariquina': 'Mariquina',\n",
    "    'San Pedro d/Paz': 'San Pedro de la Paz',\n",
    "    'San Vicente de Tagua Tagua': 'San Vicente',\n",
    "    '11 San Miguel': 'San Miguel', # From df1.apply(check_comuna, axis=1) => format issue\n",
    "    '11 La Ligua': 'La Ligua', # format issue\n",
    "    '11 San Miguel': 'San Miguel', # format issue\n",
    "    'Joaquín': 'San Joaquín', # No date !!!!! => Rosa Elena Leletier López 2012\n",
    "    '04 San Bernardo': 'San Bernardo', # format issue\n",
    "    'Alto': 'Puente Alto', # format issue,\n",
    "    'Paipote,': 'Tierra Amarilla', # format issue,\n",
    "    'El Salvador': 'Diego de Almagro',\n",
    "    'Pemuco/Ñuble': 'Pemuco',\n",
    "    '00:00:00': None, # Null values,\n",
    "    '17/12/2015': None, # Null values,\n",
    "    '21/12/2015': None, # Null values,\n",
    "    '22/12/2015': None, # Null values,\n",
    "    '26/12/2015': None, # Null values\n",
    "    'Araucanía': None, # Null values\n",
    "    'RM': 'Buin', # Esta al revéz (comuna en lugar de región)\n",
    "}\n",
    "def fix_comuna(comuna):\n",
    "    if type(comuna) == str:\n",
    "        comuna = comuna.strip()\n",
    "    if comuna in lugar_replacements:\n",
    "        return lugar_replacements[comuna]\n",
    "    else:\n",
    "        return comuna\n",
    "df_parsed['comuna'] = df_parsed.old_lugar.apply(fix_comuna)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], dtype: object)"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check comunas\n",
    "comunas = pd.read_csv('data/BDCUT_CL__CSV_UTF8.csv').COMUNA_NOMBRE\n",
    "def check_comuna(row):\n",
    "    #print(row)\n",
    "    comuna = row['comuna']\n",
    "    if type(comuna) == str:\n",
    "        comuna = comuna.strip()\n",
    "        if comuna not in comunas.values:\n",
    "            return 'Error @ {} => {}'.format(row['Lugar'], comuna)\n",
    "df_parsed.apply(check_comuna, axis=1).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "regiones = pd.read_csv('data/BDCUT_CL__CSV_UTF8.csv').REGION_NOMBRE\n",
    "\n",
    "def fix_region(region):\n",
    "    region_replacements = {\n",
    "        'I': 'Tarapacá',\n",
    "        'II': 'Antofagasta',\n",
    "        'III': 'Atacama',\n",
    "        'III Atacama': 'Atacama',\n",
    "        'IV': 'Coquimbo',\n",
    "        'V': 'Valparaíso',\n",
    "        'Cabildo': 'Valparaíso',\n",
    "        'VI': 'Región del Libertador Gral. Bernardo O\\'Higgins',\n",
    "        'O\\'Higgins': 'Región del Libertador Gral. Bernardo O\\'Higgins',\n",
    "        'O’Higgins': 'Región del Libertador Gral. Bernardo O\\'Higgins',\n",
    "        'VII': 'Región del Maule',\n",
    "        'VII Maule': 'Región del Maule',\n",
    "        'Maule': 'Región del Maule',\n",
    "        'El Maule': 'Región del Maule',\n",
    "        'VIII': 'Región del Biobío',\n",
    "        'Bio Bio': 'Región del Biobío',\n",
    "        'Bío Bío': 'Región del Biobío',\n",
    "        'Bío-Bío': 'Región del Biobío',\n",
    "        'Ñuble': 'Región de Ñuble',\n",
    "        'IX': 'Región de la Araucanía',\n",
    "        'Araucanía': 'Región de la Araucanía',\n",
    "        'IX Araucanía': 'Región de la Araucanía',\n",
    "        'La Araucanía': 'Región de la Araucanía',\n",
    "        'X': 'Región de Los Lagos',\n",
    "        'Los Lagos': 'Región de Los Lagos',\n",
    "        'XI': 'Atacama',\n",
    "        'XII': 'Región Aisén del Gral. Carlos Ibáñez del Campo',\n",
    "        'Aysen': 'Región Aisén del Gral. Carlos Ibáñez del Campo',\n",
    "        'RM': 'Región Metropolitana de Santiago',\n",
    "        'Rm': 'Región Metropolitana de Santiago',\n",
    "        'Metropolitana': 'Región Metropolitana de Santiago',\n",
    "        'Buin': 'Región Metropolitana de Santiago',\n",
    "        'XIV': 'Región de Los Ríos',\n",
    "        'Los Rios': 'Región de Los Ríos',\n",
    "        'Los Ríos': 'Región de Los Ríos',\n",
    "        'XV': 'Arica y Parinacota',\n",
    "    }\n",
    "    for region_replacement in region_replacements:\n",
    "        if str(region).strip() == region_replacement:\n",
    "            return region_replacements[region_replacement]\n",
    "    return region\n",
    "df_parsed['Region'] = df_parsed.old_region.apply(fix_region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16,)"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check region (15 + None = 16)\n",
    "df_parsed.Region.unique().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing: nan\n"
     ]
    }
   ],
   "source": [
    "for region in df1.Región.apply(fix_region).unique():\n",
    "    if region not in regiones.unique():\n",
    "        print('Missing: {}'.format(region))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['old_fecha_y_lugar', 'old_region', 'Nombre', 'Edad', 'Ocupación',\n",
       "       'Hecho', 'Vsexual', 'Tipo Femicidio', 'Femicida', 'Edad femicida',\n",
       "       'Relación', 'Suicidio', 'Ocupación femicida', 'Antecedentes',\n",
       "       'Denuncia/M cautelar', 'Categoría delito/ Ley Femicidio',\n",
       "       'Sentencia', 'source', 'Sernam', 'Situación judicial', 'Tribunal',\n",
       "       'Prensa', 'Fecha', 'old_lugar', 'Nacionalidad / Etnia',\n",
       "       'Nacionalidad / Etnia femicida', 'Información medios',\n",
       "       'Información medios 2', 'comuna', 'Region'], dtype=object)"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_parsed.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export with col order\n",
    "col_order = [\n",
    "    'old_fecha_y_lugar',\n",
    "    'Fecha',\n",
    "    'comuna',\n",
    "    'old_region',\n",
    "    'Region',\n",
    "    'Nombre',\n",
    "    'Edad',\n",
    "    'Ocupación',\n",
    "    'Hecho',\n",
    "    'Vsexual',\n",
    "    'Tipo Femicidio',\n",
    "    'Femicida',\n",
    "    'Edad femicida',\n",
    "    'Relación',\n",
    "    'Suicidio',\n",
    "    'Ocupación femicida',\n",
    "    'Antecedentes',\n",
    "    'Denuncia/M cautelar',\n",
    "    'Categoría delito/ Ley Femicidio',\n",
    "    'Sentencia',\n",
    "    'source',\n",
    "    'Sernam',\n",
    "    'Situación judicial',\n",
    "    'Tribunal',\n",
    "    'Prensa',\n",
    "    'Nacionalidad / Etnia',\n",
    "    'Nacionalidad / Etnia femicida',\n",
    "    'Información medios',\n",
    "    'Información medios 2'\n",
    "]\n",
    "df_parsed[col_order].to_csv('preview.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'Fecha y lugar': 7,\n",
       "         'Región': 10,\n",
       "         'Nombre': 10,\n",
       "         'Edad': 10,\n",
       "         'Ocupación': 10,\n",
       "         'Hecho': 10,\n",
       "         'Vsexual': 10,\n",
       "         'Tipo Femicidio': 10,\n",
       "         'Femicida': 10,\n",
       "         'Edad femicida': 10,\n",
       "         'Relación': 10,\n",
       "         'Suicidio': 10,\n",
       "         'Ocupación femicida': 10,\n",
       "         'Antecedentes': 10,\n",
       "         'Denuncia/M cautelar': 10,\n",
       "         'Categoría delito/ Ley Femicidio': 10,\n",
       "         'Sentencia': 10,\n",
       "         'source': 10,\n",
       "         'Sernam': 8,\n",
       "         'Situación judicial': 7,\n",
       "         'Tribunal': 7,\n",
       "         'Prensa': 1,\n",
       "         'Fecha': 3,\n",
       "         'Lugar': 3,\n",
       "         'Nacionalidad / Etnia': 3,\n",
       "         'Nacionalidad / Etnia femicida': 3,\n",
       "         'Información medios': 3,\n",
       "         'Información medios 2': 3})"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count fields\n",
    "from collections import Counter\n",
    "\n",
    "counter = Counter()\n",
    "for dataframe in dataframes:\n",
    "    counter.update(dataframe.columns)\n",
    "counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n"
     ]
    }
   ],
   "source": [
    "# Check cols with same name\n",
    "def duplicated_varnames(df):\n",
    "    \"\"\"Return a dict of all variable names that \n",
    "    are duplicated in a given dataframe.\"\"\"\n",
    "    repeat_dict = {}\n",
    "    var_list = list(df) # list of varnames as strings\n",
    "    for varname in var_list:\n",
    "        # make a list of all instances of that varname\n",
    "        test_list = [v for v in var_list if v == varname] \n",
    "        # if more than one instance, report duplications in repeat_dict\n",
    "        if len(test_list) > 1: \n",
    "            repeat_dict[varname] = len(test_list)\n",
    "    return repeat_dict\n",
    "\n",
    "for dataframe in dataframes:\n",
    "    print(duplicated_varnames(dataframe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
